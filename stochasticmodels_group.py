# -*- coding: utf-8 -*-
"""StochasticModels_Group.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/113oBmb5XQP6I5Q6cjAbnIOuzS-oqA9sg

# <b>Assignment</b>
# Stochastic Models

## Importing libraries
"""

import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn
from collections import Counter

seaborn.set_theme(style="darkgrid")

"""## Setting up the data

Set ticker in the following cell, and rerun all cells if required.
"""

ticker = "^NSEI"

stock = yf.Ticker(ticker)
hist = stock.history(period="max")
hist['Close'].plot()
delt = list(hist.index)[-1] - list(hist.index)[0]
print(f"Historical data totals {len(hist)} observations over {delt.days} days.")

hist.index[0].date()

"""Run either (not both) of the following sections based on which averages are required.

### Using Monthly Averages
"""

data = hist.drop(['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits'], axis=1)
mon_avgs = data.groupby([data.index.year, data.index.month]).mean()
mon_stds = data.groupby([data.index.year, data.index.month]).std()

mon_dt = pd.concat([mon_avgs, mon_stds], keys = ['Monthly_Avg', "Monthly_Std"], axis=1)
mon_dt.reset_index(level=[0,1], names=['Year', 'Month'], inplace=True)
mon_dt['yearmon'] = mon_dt['Year'].astype(str) + '-' + mon_dt['Month'].astype(str)
mon_dt.columns = mon_dt.columns.droplevel(1)
mon_dt = mon_dt.drop(['Year', 'Month'], axis=1)

data['yearmon'] = data.index.year.astype(str) + '-' + data.index.month.astype(str)
data = data.reset_index()
data = data.merge(mon_dt, on='yearmon', how='left')
data = data.set_index('Date')
# data.drop('yearmon', axis=1, inplace=True)

avg_col = 'Monthly_Avg'
std_col = 'Monthly_Std'

"""### Using Rolling Averages

Alternatively, we obtain our rolling averages and standard deviations. We then create separate features for our eventual state space.
"""

# data = hist.drop(['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits'], axis=1)
# data['Rolling_Avg'] = data['Close'].rolling(7).mean()
# data['Rolling_Std'] = data['Close'].rolling(7).std()
# data = data[6:].copy()

# avg_col = 'Rolling_Avg'
# std_col = 'Rolling_Std'

"""### State Space

We model the closing price as being in one of six states:
- `Beyond 2`: Over two standard deviations above the moving average.
- `Between 1 and 2`: Between one and two standard deviations above the moving average.
- `Between 0 and 1`: Under one standard deviation above the moving average.
- `Between 0 and -1`: Under one standard deviation below the moving average.
- `Between -1 and -2`: Between one and two standard deviations below the moving average.
- `Beyond 2`: Over two standard deviations above the moving average.
"""

def state_map(x):
  if x['Close'] > x[avg_col] + (2 * x[std_col]):
    return 'Bull Run'
  elif x['Close'] > x[avg_col] + x[std_col]:
    return 'Strong Uptick'
  elif x['Close'] > x[avg_col]:
    return 'Mild Gain'
  elif x['Close'] < x[avg_col] - (2 * x[std_col]):
    return 'Market Correction'
  elif x['Close'] < x[avg_col] - x[std_col]:
    return 'Bearish Trend'
  elif x['Close'] < x[avg_col]:
    return 'Mild Dip'
  else:
    return None

data['State'] = data.apply(state_map, axis=1)

"""<i>Sanity check:</i> Let us make sure that every row has been labelled."""

exc_tru = len(data[data['State'].isna()])
print(f"Number of rows without State labels: {exc_tru}")

"""## Markov Chain

First, we generate our transition probabilities matrix.
"""

trans_probs = {}
states = ['Bull Run','Strong Uptick', 'Mild Gain', 'Mild Dip', 'Bearish Trend', 'Market Correction']

for current_state in states:
    state_transitions = data['State'].shift(-1).loc[(data['State'] == current_state) & (data.index != data.index[-1])]
    total_transitions_from_state = len(state_transitions)

    if total_transitions_from_state == 0:
        continue

    state_transition_counts = Counter(state_transitions)
    probabilities = {
        next_state: count / total_transitions_from_state
        for next_state, count in state_transition_counts.items()}

    trans_probs[current_state] = probabilities

tr_mat = pd.DataFrame.from_dict(trans_probs, orient='index')
tr_mat = tr_mat.fillna(0)
tr_mat = tr_mat.to_numpy()

tr_mat

"""<i>Sanity check:</i> Given that sum of probabilities of each row is 1, ie. $\sum_j^6 \pi_{ij} = 1$; we check this below."""

for i in range(len(tr_mat)):
  print(f"Sum of probabilities of row {i+1} is {int(np.sum(tr_mat[i]).round(1))}.")

# Define a small positive value to add to diagonal elements of the transition matrix
epsilon = 1e-6

# Define the number of time steps for the simulation
num_steps = 10000

# Initialize a list to store the simulated states for this chain
simulated_states = []

# Initialize the current state for this chain
current_state_index = np.random.randint(len(states))  # Random initial state

# Run the Metropolis-Hastings simulation for this chain
for t in range(num_steps):
    # Sample a proposed next state based on transition probabilities
    proposed_next_state_index = np.random.choice(len(states), 1, p=tr_mat[current_state_index])

    # Get the transition probability for the proposed transition
    transition_prob_proposed = tr_mat[current_state_index, proposed_next_state_index[0]]

    # Get the transition probability for staying in the current state
    transition_prob_current = tr_mat[current_state_index, current_state_index]

    # Accept or reject the proposed state based on Metropolis-Hastings acceptance criteria
    acceptance_ratio = min(1, transition_prob_proposed / max(transition_prob_current, epsilon))

    if np.random.rand() <= acceptance_ratio:
        current_state_index = proposed_next_state_index[0]

    # Store the simulated state for this chain
    simulated_states.append(states[current_state_index])

# Print the simulated states for this chain
print("Simulated States for the Chain:")
print(simulated_states)

# Calculate the posterior distribution from the simulated states
posterior_distribution = dict(Counter(simulated_states))

# Normalize to obtain probabilities (relative frequencies)
total_samples = len(simulated_states)
posterior_distribution_probabilities = {state: count / total_samples for state, count in posterior_distribution.items()}

# Ensure that all states have probabilities, including those not observed in the simulation
for state in states:
    posterior_distribution_probabilities.setdefault(state, 0.0)

# Sort the posterior distribution by state name
sorted_posterior_distribution = {state: posterior_distribution_probabilities[state] for state in states}

# Print the posterior distribution
for state, probability in sorted_posterior_distribution.items():
    print(f"State: {state}, Probability: {probability:.4f}")

state_colours = ['limegreen', 'forestgreen', 'skyblue', 'red', 'darkred', 'black']
state_colours = dict(zip(states, state_colours))

# Convert the posterior distribution to a list of probabilities sorted by state order
posterior_probabilities = [posterior_distribution_probabilities[state] for state in states]

# Plot the posterior distribution as a bar graph with custom colors
plt.figure(figsize=(8, 4))
plt.bar(states, posterior_probabilities, color=[state_colours[state] for state in states])
plt.xlabel('Price deviation State space')
plt.ylabel('Probability')
plt.title('Posterior Distribution for Price Deviations')
plt.ylim(0, 1)  # Set the y-axis limit to the range [0, 1] (probabilities)
plt.xticks(rotation=45)  # Rotate the x-axis labels for readability
plt.show()

# Initialize the initial state probability distribution
state = np.array([[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]])

# Initialize a historical record of the state probability distribution
stateHist = state

# Create a DataFrame to store the historical state probability distribution
dfStateHist = pd.DataFrame(state)

# Initialize a variable to store a distribution history (not used in the code)
distr_hist = [[0, 0, 0, 0, 0, 0]]

# Simulate the state probability distribution over 200 time steps
for x in range(10000):
    # Update the state probability distribution using matrix multiplication (Markov Chain transition)
    state = np.dot(state, tr_mat)

    # Append the current state probability distribution to the historical record
    stateHist = np.append(stateHist, state, axis=0)

    # Create a DataFrame to store the historical state probability distribution
    dfDistrHist = pd.DataFrame(stateHist)

# Plotting graph with customized labels
plt.figure(figsize=(10, 5))

# Loop through each state and plot its line with a label
for i, state_name in enumerate(states):
    seaborn.lineplot(data=dfDistrHist[i], label=state_name, lw=2)

plt.xlabel("Iteration")
plt.ylabel("Probability")
plt.title("Plot of Price Deviation in each iteration")
plt.legend(title="Deviation", loc='upper right')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming states is a list of state names and dfDistrHist is a list of dataframes
plt.figure(figsize=(10, 5))

# Loop through each state and plot its line with a label
for i, state_name in enumerate(states):
    sns.lineplot(data=dfDistrHist[i], label=state_name, lw=2)

plt.xlabel("Iteration")
plt.ylabel("Probability")
plt.title("Plot of Price Deviation in each iteration")
plt.legend(title="Deviation", loc='upper right')
plt.show()

states

codes = [5, 4, 3, 2, 1, 0]
state_to_code = dict(zip(states, codes))

# Convert the simulated_states to numerical codes
simulated_states_numeric = [state_to_code[state] for state in simulated_states]

# Autocorrelation Plot
plt.figure(figsize=(10, 5))
pd.plotting.autocorrelation_plot(simulated_states_numeric)
plt.xlabel("Lag")
plt.ylabel("Autocorrelation")
plt.title("Autocorrelation Plot")
plt.show()

# Create a list to store the state indices for the simulated states
simulated_state_indices = [states.index(state) for state in simulated_states]

# Create a trace plot
plt.figure(figsize=(10, 5))
plt.plot(range(num_steps), simulated_state_indices, marker='o', linestyle='-', markersize=2)
plt.xticks(range(0, num_steps, 1000), range(0, num_steps, 1000))
plt.xlabel("Time Step")
plt.ylabel("State Index")
plt.title("Trace Plot for Checking Convergence")
plt.yticks(range(len(states)), states)
plt.grid(True)
plt.show()

dfDistrHist.tail(10)